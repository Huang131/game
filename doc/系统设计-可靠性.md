# 排行榜系统可靠性设计方案

## 一、高可用架构设计：消除单点故障

### 1. 应用层：无状态化与横向扩展

* **无状态服务设计**：将排行榜核心逻辑（分数更新、排名计算、查询）封装为无状态 API，通过负载均衡（如 Nginx/LVS）分发流量，支持动态扩容缩容。

* **多实例冗余部署**：部署 ≥2 个应用实例到不同物理机 / 容器 / 虚拟机，通过 Kubernetes/Docker Swarm 实现自动故障转移。
    * **流量调度策略**：轮询、最小连接数、IP 哈希（确保同一用户请求路由到固定实例）。
    * **流量保护机制**：
        * **熔断**：使用 Hystrix/Sentinel，当依赖服务错误率 ≥50% 且请求量 ≥100 时，自动熔断并返回默认值（如 “系统繁忙”）。
        * **限流**：通过令牌桶算法限制单个用户每秒请求 ≤5 次，全局 QPS ≤10000 次。

### 2. 数据层：分布式存储与冗余

* **核心存储选型**

  | 场景 | 方案 | 特点 |
    |---|---|---|
  | 实时高频更新 | Redis Cluster/TiDB | 分片集群+3副本 |
  | 历史数据存储 | MySQL主从/HBase | 结构化/非结构化存储 |


* **高可用副本机制**：
    * **主从复制**：采用半同步模式（至少 1 个从节点确认写操作），降低数据丢失风险；通过 MySQL MHA/Redis Sentinel，主节点故障时 30 秒内切换到从节点。
    * **强一致性协议**：关键数据（如用户分数）使用 Raft/Paxos 协议（如 Etcd），确保多数节点写入成功后返回。

### 3. 缓存层：热点数据加速与容灾

* **分布式缓存集群**：使用 Redis Cluster（16384 分片槽），开启 RDB（每 5 分钟全量备份） + AOF（每秒日志持久化），故障时通过 Sentinel 自动恢复。
* **缓存策略**：
    * **热点数据（Top 100）**：设置 TTL = 5 分钟，通过异步线程定期刷新避免缓存击穿。
    * **穿透防护**：未命中数据缓存空值（TTL = 1 分钟），防止恶意高频查询击穿数据库。

* **缓存与存储一致性**：
  ```go
  // 写操作：先更新数据库，再失效缓存
  func updateScore(playerID string, score int) {
      if db.Update(playerID, score) != nil {
          retryUpdateDB(playerID, score)
      }
      cache.Del("rank:" + playerID)
  }

## 二、数据一致性与完整性保障

### 1. 原子性操作与事务

#### 单节点事务

使用数据库本地事务（如 MySQL 的 InnoDB 事务）保证 “更新分数” 与 “维护排名” 的原子性：

```sql
BEGIN
TRANSACTION;
UPDATE players
SET score = 1000
WHERE id = 'player1';
INSERT INTO rank_history (player_id, score, timestamp)
VALUES ('player1', 1000, NOW());
COMMIT;  
```

#### 分布式事务

TCC 模式（适用于强一致性场景）

* Try 阶段：预占资源（如冻结分数变更配额）
* Confirm 阶段：正式提交变更
* Cancel 阶段：异常时回滚预占资源

最终一致性：通过 Kafka 消息队列异步处理，消息持久化存储并支持 3 次重试，消费端实现幂等接口（如根据唯一 ID 去重）。

### 2. 并发控制与防竞争

乐观锁：通过版本号（version字段）校验并发更新

```sql
UPDATE players
SET score   = 1000,
    version = version + 1
WHERE id = 'player1'
  AND version = 5;  
```

分布式锁：全局排名计算（如每日 0 点更新总榜）时，使用 Redis Redlock 获取分布式锁

### 3. 数据校验与补偿

实时校验：写入时校验参数合法性，分数必须≥0，用户 ID 长度≤32 字符，时间戳必须为 UTC 时间
异步对账：定时任务（每小时）对比缓存、数据库、备份存储的数据一致性

## 三、容错与恢复机制

### 1. 故障隔离与自愈

**分区容错设计** 遵循 CAP 理论，根据业务场景选择：

* 实时排名查询（优先可用性 A）：允许分区时从旧副本读取数据，最终通过 Gossip 协议同步
* 分数更新（优先一致性 C）：等待多数节点确认后返回成功。

**自动恢复策略**

* 应用层：Kubernetes 通过readinessProbe检测容器状态，故障容器 30 秒内重启并重建
* 数据层：Redis Sentinel 每 2 秒检测主节点状态，故障时 10 秒内选举新主节点并通知应用层更新连接地址

### 2.备份与容灾

三级备份体系

| 备份类型 | 频率      | 存储位置         | 恢复时间（RTO） | 数据丢失容忍（RPO） |
   |------|---------|--------------|-----------|-------------|
| 实时日志 | 同步 / 异步 | 本地磁盘 + 分布式存储 | 秒级        | 最多 1 秒数据丢失  |
| 增量备份 | 每 15 分钟 | 同机房备份集群      | 10 分钟     | 最多 15 分钟数据  |
| 全量备份 | 每日 0 点  | 异地灾备中心（跨可用区） | 1 小时      | 24 小时数据     |

容灾演练：每月模拟机房断电故障，验证灾备中心能否在 30 分钟内接管服务，确保数据恢复准确率≥99.99%。

### 3. 优雅降级与限流

**降级策略** 高峰时段（如晚上 8 点）自动降级非核心功能：

* 关闭实时排名更新，改为每 5 分钟批量计算。
* 查询接口返回 1 分钟前的缓存数据，并附加提示 “排名可能存在延迟”。

**限流规则**

* 全局限流：通过 Nginx 限流模块，限制单个 IP 每秒请求≤10 次。
* 服务内限流：使用 Go 的sync/semaphore控制并发处理量，超出阈值时返回 HTTP 503 Service Unavailable。

## 四、监控与运维：全链路可观测性

### 1. 立体化监控体系

核心监控指标

| 层级  | 指标项          | 阈值示例                          | 报警方式    |
   |-----|--------------|-------------------------------|---------|
| 应用层 | QPS、响应时间、错误率 | 错误率 > 5%，RT>500ms             | 短信 + 邮件 |
| 数据层 | 数据库连接数、慢查询次数 | 连接数 > 90% 阈值，慢查询 > 100 次 / 分钟 | 企业微信通知  |
| 缓存层 | 命中率、内存使用率    | 命中率 <80%，内存> 90%              | 电话报警    |

日志追踪：为每个请求生成唯一 Trace ID，记录关键操作日志：
使用 ELK Stack 集中存储日志，支持秒级检索和链路追踪。

### 2. 自动化运维工具链

**配置管理**
采用基础设施即代码（IaC），通过 Terraform 管理服务器、数据库、负载均衡器配置，变更记录自动审计。

**故障自愈脚本**
预定义常见故障处理逻辑（如重启 Redis 节点、切换数据库主从），通过 Jenkins Pipeline 一键执行：

## 五、典型场景应对策略

### 1. 突发流量冲击

预案

* Kubernetes 根据 CPU 使用率（>80%）自动扩容应用实例，5 分钟内实例数从 10 扩展至 50。
* 开启 CDN 缓存 Top 1000 排名页面，静态资源命中率≥95%。

### 2. 数据中心级故障

架构：采用多活架构（Active-Active），跨地域部署 3 个数据中心（华北、华东、华南），通过 Anycast DNS 将流量路由到最近可用区；故障时通过 Global Traffic
Manager 自动切换，切换时间≤30 秒。

### 3. 人为操作失误

防护：敏感操作（如删除数据库表）需二级审批，操作日志实时同步到审计系统；误删数据恢复：通过 Binlog 解析工具（如 MySQL Binlog2SQL）生成回滚语句，10
分钟内完成数据恢复。

## 六、总结

通过分层冗余架构（应用层无状态扩展、数据层多副本冗余）、一致性保障机制（事务、锁、对账）、自动化容错体系（备份、恢复、降级）、全链路监控（指标、日志、报警），可构建满足以下目标的排行榜系统：

* 可用性：99.99%（年均故障时间≤52 分钟）。
* 数据一致性：核心操作（分数更新）强一致性，非核心操作最终一致性。
* 可恢复性：故障恢复时间（RTO）≤1 小时，数据丢失（RPO）≤1 分钟。

